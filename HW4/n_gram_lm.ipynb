{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vQjltCZ4brpA"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6gmGzGIa0cL"
   },
   "source": [
    "Вспомним, как писать бесконечные генераторы с помощью ```yield```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2Lg74Y9UH-L",
    "outputId": "7c099b47-89dd-4854-8059-004703232a80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def num_generator():\n",
    "    start = 0\n",
    "    while True:\n",
    "        yield start\n",
    "        start += 1\n",
    "\n",
    "gen = num_generator()\n",
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fmxR_jgXuYY"
   },
   "source": [
    "А если хочется получить сразу несколько первых элементов из генератора?\n",
    "\n",
    "**Задание** Напишите функцию-генератор, которая будет выдавать элементы до тех пор, пока не наберется нужное количество (`n`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YuEU7h3YW_E4",
    "outputId": "c36807ca-62af-4669-e86d-8ebfbe93214c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def take(generator, n):\n",
    "    gen = generator\n",
    "    start = 0\n",
    "    while start < n:\n",
    "        yield next(gen)\n",
    "        start += 1\n",
    "        \n",
    "list(take(num_generator(), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1s7TVDJaddz"
   },
   "source": [
    "**Задание** Напишите генератор, который будет выдавать только четные числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5E0D1xdNVsxf",
    "outputId": "96b846a6-068d-4f5e-9d2e-c1487910a311"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def even_num_generator(num_generator):\n",
    "    gen = num_generator\n",
    "    start = 0\n",
    "    while True:\n",
    "        if (start % 2) == 0:\n",
    "            yield next(gen)\n",
    "        else:\n",
    "            next(gen)\n",
    "        start += 1\n",
    "\n",
    "list(take(even_num_generator(num_generator()), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppitp0YmbgqI"
   },
   "source": [
    "## N-граммная языковая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15fhnu6GtlGv",
    "outputId": "f5bb05c4-188d-4e6d-e174-f1c6e625f35a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гудели как-то мы с друзьями ночкой тёмною,\r\n",
      "И спьяну, сдуру я признался им в одном:\r\n",
      "\"В десанте нет мне равных, - говорю, - не стрёмно мне\r\n",
      "Застыть на целый день в засаде под кустом!\"\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head poetry.txt -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BC1cbnJRbwFx"
   },
   "source": [
    "***Задание*** Посчитайте частотности слов в файле за ```O(1)``` памяти, то есть без ```f.read()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jJUv-BZbuRW",
    "outputId": "5725ee67-28f4-4efd-91fc-6d2c74c06a20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('и', 111377), ('в', 75436), ('не', 50914), ('я', 38324), ('на', 34592), ('как', 26130), ('с', 25474), ('что', 21110), ('ты', 17929), ('а', 16292), ('но', 15882), ('он', 14068), ('мне', 14028), ('за', 11009), ('все', 10842), ('к', 10678), ('по', 9729), ('о', 9728), ('мы', 9312), ('так', 8698), ('от', 8687), ('у', 7679), ('из', 7599), ('меня', 7045), ('где', 6698), ('то', 5901), ('его', 5855), ('ни', 5790), ('под', 5781), ('нет', 5711), ('их', 5599), ('когда', 5592), ('же', 5409), ('над', 5303), ('это', 5257), ('мой', 5165), ('тебя', 4949), ('вот', 4824), ('только', 4692), ('она', 4672), ('да', 4665), ('без', 4643), ('до', 4551), ('бы', 4484), ('там', 4468), ('был', 4443), ('для', 4384), ('кто', 4334), ('нам', 4065), ('нас', 3964), ('ли', 3865), ('тебе', 3838), ('всё', 3832), ('вы', 3732), ('во', 3681), ('ее', 3590), ('еще', 3573), ('сердце', 3530), ('чтоб', 3436), ('лишь', 3368), ('быть', 3210), ('если', 3198), ('жизнь', 3172), ('есть', 2957), ('они', 2871), ('может', 2757), ('было', 2744), ('день', 2707), ('здесь', 2701), ('моя', 2691), ('уж', 2614), ('твой', 2592), ('жизни', 2528), ('уже', 2527), ('пусть', 2523), ('со', 2516), ('будет', 2434), ('любви', 2419), ('ночь', 2385), ('ж', 2370), ('любовь', 2350), ('всех', 2324), ('ней', 2283), ('чем', 2241), ('вдруг', 2237), ('мир', 2224), ('тот', 2159), ('моей', 2157), ('б', 2129), ('или', 2093), ('теперь', 2084), ('друг', 2077), ('ей', 2047), ('вас', 2009), ('ему', 1992), ('хоть', 1955), ('ведь', 1934), ('опять', 1913), ('тобой', 1912), ('свой', 1898)]\n"
     ]
    }
   ],
   "source": [
    "word_counts = Counter()\n",
    "with open('poetry.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        tokens = word_tokenize(line)\n",
    "        for t in tokens:\n",
    "            if re.search('[а-яА-ЯЁё]', t):\n",
    "                word_counts[t.lower()] += 1\n",
    "\n",
    "print(word_counts.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB1HcZyNcTN1"
   },
   "source": [
    "Для создания нашей N-граммной модели будем накапливать статистику для всех строк стихотворений. \n",
    "Генерировать стихотворения будем построчно. Для этого нужно научить генерировать \"первое слово\" и \"последнее слово\" строки.\n",
    "\n",
    "**Задание** Напишите `parser` - функцию, которая будет выдавать поток токенов из файла. При этом каждая \"строка\" стихотворения должна начинаться с токена ```<BOS>``` и ```<EOS>```.\n",
    "Добавьте предобработку: фильтруйте все строки длиной менее 20 символов. Удалите все знаки препинания. Приведите к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "5IM9HOBEchqy"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def parser(path):\n",
    "    yield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHKOg_mPdErP"
   },
   "source": [
    "Напишем N-граммную языковую модель по стишкам.\n",
    "\n",
    "Языковая модель умеет оценивать вероятности $\\mathbf{P}(w_1, \\ldots, w_n) = \\prod_k \\mathbf{P}(w_k|w_{k-1}, \\ldots, w_{1})$.\n",
    "\n",
    "N-граммная языковая модель приближает эту вероятность, используя предположение, что вероятность токена зависит только от недавней истории: $\\mathbf{P}(w_k|w_1, \\ldots, w_{k-1}) = \\mathbf{P}(w_k|w_{k-1}, \\ldots, w_{k-N + 1})$.\n",
    "\n",
    "Для начала нужно собрать статистику. Для простоты будем работать с биграмной моделью, а значит - нужно собрать информацию:\n",
    "\n",
    "- о биграммных частотностях $(w_{i-1}) \\to C(w_i)$\n",
    "- о триграммных частотностях $(w_{i-2}, w_{i-1}) \\to C(w_i)$\n",
    "\n",
    "Также хочется сохранять в статистику n-gram информацию о начале и коцне стишка.\n",
    "\n",
    "**Задание** Напишите функцию, которая будет из потока токенов формировать и выдавать наружу пары (ngram, next_word).\n",
    "\n",
    "Каждый стишок должен начинаться с токена ```<BOS>``` и заканчиваться ```<EOS>``` (beginning of sequence, end of sequence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "uFd5wu12de8o"
   },
   "outputs": [],
   "source": [
    "def compose_ngram(tokens_stream):\n",
    "\n",
    "    token = next(tokens_stream)\n",
    "    yield\n",
    "    # Подсказки:\n",
    "    # Что сохраняем, если token --> <BOS>?\n",
    "    # Что делаем, если token --> <EOS>?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pF3D8X4jis0r"
   },
   "source": [
    "Соберем статистику:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_counter = defaultdict(Counter)\n",
    "for ngram in compose_ngram(parser('poetry.txt')):\n",
    "    ngrams_counter[tuple(ngram[0])][ngram[1]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdFzXmxLjJrk"
   },
   "source": [
    "Теперь генерировать будем так: есть стартовый токен. Проверяем последнюю триграмму в статистике. Если есть, генерируем с помощью нее новое слово. Если нет, ищем биграму (она должна быть).\n",
    "Если засемплили ```<EOS>``` --> завершаем генерацию и строку.\n",
    "Генерировать будем четверостишья (стихотворения из 4 строк)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "cCy_cUEdnYLH"
   },
   "outputs": [],
   "source": [
    "def sample_token(ngrams_counter, ngram):\n",
    "    probs = np.array(list(ngrams_counter[ngram].values()))\n",
    "    probs = probs / np.sum(probs)\n",
    "    return np.random.choice(list(ngrams_counter[ngram]), p=probs)  \n",
    "  \n",
    "def generate_line(ngrams_counter):\n",
    "    buffer = ['<BOS>']\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3XyqgnbLHK_",
    "outputId": "1bc720c4-8491-4a3e-cf42-e6085f9ba9e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "как пешеходу в зной лаская полуденный\n",
      "на току молотящих снопы спозаранок\n",
      "лишь в честь убитого сердца толпою\n",
      "где можешь ты обжора ах злодей\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    print(' '.join(generate_line(ngrams_counter)).strip('<EOS> <BOS>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "n-gram poroshok.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
